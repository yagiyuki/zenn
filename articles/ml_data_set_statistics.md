---
title: "機械学習モデルの評価に必要なデータ数を見積もる 〜機械学習の仕事に統計を使ってみる〜"
emoji: "👻"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["統計検定", "統計学", "Python", "機械学習"]
published: true
---

この記事では、母比率の区間推定を用いて機械学習モデルの評価に必要なデータ数を見積もる方法を書きます。
以下の記事で、母比率の区間推定で機械学習モデルを評価する方法を書きましたがその続編です。
https://zenn.dev/yagiyuki/articles/ml_test_statistics

:::message
本記事で記載した内容は、私的なアイディアをまとめたものになります。
機械学習モデルの評価方法として確立したものではない点をご認識ください。
:::

## 機械学習モデルの評価とは?

機械学習モデルの評価とは、「学習したデータとは別のデータでモデルの性能を評価すること」を指します。
性能評価の指標としてよく使うのはこのあたりです。

* 正解率 → 全評価データに対する正答率
* 適合率 → モデルが正と判定した結果のうち正しいものの割合
* 再現率 → 評価データのうち正であるものに対して正しくモデルが予測できた割合

慣れないうちは非常にとっつきにくい用語と思います。
以下の記事にすごくわかりやすくまとまっているものがありますので、慣れていない人はこちらをみるとよいです。
https://qiita.com/FukuharaYohei/items/be89a99c53586fa4e2e4


## 母比率の区間推定を使って評価データの数を見積もる

例えば、評価件数が1件である場合、それは少なすぎと断言できるでしょう。
では、100件、1000件、5000件の場合はどうでしょうか?
なかなか判断がつきにくいところと思います。
必要な評価データの数を見積もるために母比率の区間推定を使ってみます。

:::message
代表的な機械学習モデルの評価方法として「ホールドアウト法」があります。
データを「学習用」「評価用」に7対3などに分けて学習モデルを評価する方法です。
この方法には「評価用」のデータ数を絶対指標で見積もれないという欠点があります。
※例えばデータセットが1000件あったとすると評価データが300件になるが、果たしてこれで正確な評価ができるのか?
:::


### 母比率の区間推定とは?

詳しくは以下の記事にまとめているので見てほしいのですが、ざっくりレベルで説明しておきます。
https://zenn.dev/yagiyuki/articles/ml_test_statistics

ある商品レビューサイトの悪質な口コミデータを判定する機械学習モデルを評価することを考えます。
評価対象はWebサイトで扱う口コミデータになります。(モデルの学習に使ったものは除く)
評価対象が仮に1000万件あった場合、それらすべてを評価することは可能でしょうか?
人的コストや金銭的コストを考えると難しい場合がほとんどです。
1000万件のうちいくつかのデータをサンプリングして評価をすることになるでしょう。

サンプリングしたデータから評価した結果から真の評価結果を推定するのが区間推定です。
ここでいう真の評価結果とは、口コミデータの全体(1000万件)に対する評価です。

区間推定は以下のように計算できます。

* 評価データから計算した評価結果(正解率など):p
* 評価データの数:n
* 標準正規分布の上側x%点(信頼区間に応じて設定):z

![](/images/population_proportion_interval2.png)

おもしろいことに、口コミデータの全体の数が100万でも1億でも計算式に変化はありません。
大数の法則や中心極限定理と関連するところですので興味がある人は勉強してみてください。

### 評価データの件数を見積もる

真の評価結果が「だいたいこの範囲に収まるよ」というのを求めるのが区間推定です。
この区間の範囲を狭くすればするとほ正確な評価ができているということになります。
つまり、期待した区間の幅に収まるような評価データの数(n)を求めればよいことになります。

![](/images/expected_interval.png)

![](/images/expected_sample_size.png)


### pythonで評価データの件数を計算

以下の基準で評価したいときに必要な評価データの数を求めます。

* p=0.8
* 期待する区間の幅=0.05(5%)
* 信頼区間=95%

```python
#
# 必要なサンプルサイズの計算
#

import numpy as np
from math import ceil

alpha, z = (0.95, 1.96)  # 信頼区間, 標準正規分布の上側x%点
p=0.8    # モデル性能(標本比率)
delta=0.05 # 求めたい母比率の幅（5%）

# サンプルサイズ
n = ceil(pow((2*z*np.sqrt(p*(1-p)))/delta, 2))
print(n) # out -> 984
```
答えは984件になります。

ちなみに、実際に984件のデータを使って母比率の区間推定をすると「0.775 < p < 0.825」となります。
つまり、以下の解釈となります。
* 評価データが984件であり、信頼区間が95%なので、95%に割合で評価結果が「77.5% 〜 82.5%」に収まる
  (評価を100回やれば95回は、77.5% 〜 82.5%となることが期待できる)
* 逆に言うと5%は、「77.5% 〜 82.5%」に収まらない結果となる


```python
import numpy as np

#
# 設定
#
alpha, z = (0.95, 1.96) # 信頼区間, 標準正規分布の上側x%点
n = 984      # 評価したテストデータの数(サンプルサイズ)
p = 0.8     # モデル性能(標本比率)

#
# 計算
#
Z = z * np.sqrt(p*(1-p) / n)
print('母比率の{}%信頼区間: {:.3f} < p < {:.3f}'.format(alpha*100, p - Z, p + Z))
```

### pを事前に設定することはできるのか?

新規で学習したモデルの場合、pの値がわからないケースがあると思います。
その場合どのようにすればよいでしょうか?
以下のような方法が考えられます。

* 期待する性能を設定しておく(正解率=0.8以上を期待するなら0.8としておく)
* p=0.5にしておく(p=0.5のとき区間の幅は最大となる。そのため評価に必要なデータ数はP0.5で最大になる)

## まとめ

母比率の区間推定を使って評価データの数が見積もる方法について考察しました。
評価データの数をどのくらいにすべきかという参考になれば幸いです。

以上です。
