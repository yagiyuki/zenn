---
title: "なぜRAGの研究が盛んだったか？〜NLP2025に参加した所感〜"
emoji: "🔎"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["rag", "nlp", "生成ai"]
published: true
---

[NLP2025](https://www.anlp.jp/proceedings/annual_meeting/2025/)に参加しました！多くの最新研究に触れる機会がありましたが、その中でも特に目を惹いたのが Retrieval-Augmented Generation (RAG) に関する研究の増加です。
昨年と比較しても、RAG関連の発表が大幅に増えた印象があります。同僚にきいても同じ感想を持った人もいたようです。
本記事では、なぜRAGの研究がこれほど盛んになっているのか について、NLP2025で得た知見をもとに整理して考察してみます。


## RAGとは？

まず、RAG（Retrieval-Augmented Generation）について簡単におさらいしておきます。

RAGは、大規模言語モデル（LLM）の生成能力と、外部の知識ベースや検索システムを統合する手法 です。従来のLLMは事前学習時のデータに基づいて応答を生成するため、最新の情報が反映されない、事実誤認（ハルシネーション）が発生する などの課題がありました。

RAGでは、以下の2つのプロセスを組み合わせることで、LLM単体の限界を克服しようとしています。

1. Retriever（検索モジュール）：外部データベースや文書コーパスから関連情報を検索し、LLMに提供する。
2. Generator（生成モジュール）：Retrieverが取得した情報を活用して、より正確で信頼性の高い応答を生成する。

![](/images/rag_architecture.png)

## RAGの研究が盛んになっている理由

### 1. LLMの限界を補うための現実的な解決策

LLMは強力な生成能力を持つものの、知識の更新が難しい という問題があります。
例えば、GPT-4oは、2024年6月までのデータを学習していると言われており、最新の情報を反映できていません。
また、企業独自のデータについても当然反映されていません。

RAGを組み合わせることで、動的に情報を取得し、より最新で正確な応答が可能になるため、企業の導入が注目されています。

RAG以外のアプローチとして、事前学習、ファインチューニング、プロンプトエンジニアリングの3つの手法が考えられます。

しかし、これらの手法には実用上の課題があります。

* 事前学習をする：独自のデータを組み込むには、巨大な計算資源が必要 であり、一部の資金が潤沢な企業しか実施できない。
* ファインチューニングをする：データの継続的な更新が困難で、コストやリソース面での制約が大きい。
* プロンプトエンジニアリング：膨大な外部情報のすべてをプロンプトエンジニアリングだけで管理することは現実的ではない。

これらの問題を考えると、**RAGが企業にとって最も現実的な解決策であり、柔軟に知識を更新できる手法として圧倒的に優位である**と私は思います。

### 2. RAGも「最適解」が出せていない

理屈の上では、RAGが企業内のドキュメントを活用する方法として現実的な方法であると考えます。
しかし、RAGも万能ではなく、現状では企業導入には多くの課題があるように見えます。

とくに企業導入するうえでは下記が課題になっていそうです。

* 回答精度の低さ
* 評価手法が確立していない

**理屈の上では最適解にみえるが、現実ては「最適な手法が見つかっていない」こと自体が、RAGの研究を推し進める最大の理由である** と考えます。


## まとめ

現在、RAGは回答精度の低さなどが原因で、幻滅期に入っているように思います。
しかし、外部知識を活用した生成AIの実用化において、RAG以外の現実的な選択肢はあまり聞いたことがありません。
事前学習やファインチューニングといった代替手法も存在しますが、これらは莫大なコストがかかり、継続的な知識更新も困難なため、多くの企業にとって実現可能な方法とは言えないと思います。

この記事に記載されている「回答精度が上がることで、2025年ますます注目されるのではないかという予想」というところには共感しました。
https://zenn.dev/knowledgesense/articles/591f560b3a6151
今後もRAGに関する研究は続き、より実用的な形へと進化していく可能性が高いと考えます。